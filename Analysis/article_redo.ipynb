{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../algorithms/')\n",
    "\n",
    "from CSOWP_SR import *\n",
    "from ExpressionTree import *\n",
    "from trainAlgorithm import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(v):\n",
    "    return 1.57 + 24.3*v\n",
    "\n",
    "X1 = np.linspace(-2, 2, 1000)\n",
    "y1 = f1(X1)\n",
    "\n",
    "def f2(v, y, w):\n",
    "    return 0.23 + 14.2*(v+y)/(3*w)\n",
    "\n",
    "v2 = np.linspace(-2, 2, 1000)\n",
    "y2 = np.linspace(-2, 2, 1000)\n",
    "w2 = np.linspace(-2, 2, 1000)\n",
    "y2 = f2(v2, y2, w2)\n",
    "\n",
    "def f11(x):\n",
    "    return 6.87 + 11*np.cos(7.23*x**3)\n",
    "\n",
    "X11 = np.linspace(-2, 2, 1000)\n",
    "y11 = f11(X11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 3\n",
    "n_generations = 10\n",
    "pop_size = 40\n",
    "random_const_range = (0, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators_op = {\"+\": lambda a,b: np.add(a,b), \"*\": lambda a,b: np.multiply(a,b),\n",
    "                \"/\": lambda a,b: np.divide(a,b), \"-\": lambda a,b: np.subtract(a,b)}\n",
    "functions_op = {\"sin\": lambda a: np.sin(a), \"cos\": lambda a: np.cos(a),\n",
    "                \"square\": lambda a: a**2, \"cube\": lambda a: a**3}\n",
    "custom_functions_dict = {\"cube\": [\"(\", \")**3\"], \"square\": [\"(\", \")**2\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_kind = \"LS\"\n",
    "func = f1\n",
    "x_range = [-1,1]\n",
    "n_points = 1000\n",
    "population = 4000\n",
    "generations = 10\n",
    "const_range = (0,15)\n",
    "dir_path = \"Outputs/article_tests/LS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Outputs/article_tests/PSO',\n",
       " 'Outputs/article_tests/LS',\n",
       " 'Outputs/article_tests/random_LS',\n",
       " 'Outputs/article_tests/differential_evolution',\n",
       " 'Outputs/article_tests/dual_annealing']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_opts = [\"PSO\", \"LS\", \"random_LS\", \"differential_evolution\", \"dual_annealing\"]\n",
    "main_path = \"Outputs/article_tests/\"\n",
    "paths = [main_path + i for i in optimization_opts]\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs(path):\n",
    "    if not os.path.exists(path+\"/data\"):\n",
    "        os.makedirs(path+\"/data\")\n",
    "    if not os.path.exists(path+\"/trees\"):\n",
    "        os.makedirs(path+\"/trees\")\n",
    "\n",
    "for path in paths:\n",
    "    create_dirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/PSO =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/PSO =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/PSO =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/PSO =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/PSO =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/PSO =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/LS =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/LS =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/LS =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/LS =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/LS =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/LS =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/random_LS =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/random_LS =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/random_LS =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/random_LS =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/random_LS =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/random_LS =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/differential_evolution =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/differential_evolution =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/differential_evolution =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/differential_evolution =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/differential_evolution =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/differential_evolution =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/dual_annealing =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Stopping algorithm because function create NaN or (+/-) infinity values even with trying new random parameters",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2152\\1691876664.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0moptimization_kind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimization_opts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdir_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moptimization_kind\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     X, y, operators, functions = testAlgorithm(func, x_range, n_points, dir_path, population, generations,\n\u001b[0m\u001b[0;32m      4\u001b[0m                                           \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconst_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconst_range\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                           \u001b[0mignore_warning\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_runs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_runs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Documents\\Coding\\Repositorios\\MyRepositories\\Symbolic-Regression\\CSOWP_SR\\Analysis\\../algorithms\\trainAlgorithm.py\u001b[0m in \u001b[0;36mtestAlgorithm\u001b[1;34m(func, x_range, n_points, dir_path, population, generations, max_expression_size, normalize, const_range, normalize_range, ignore_warning, overwrite, n_runs, operators, functions, weights, island_interval, optimization_kind, custom_functions_dict)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0moutput_AEG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_AEG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msexp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Documents\\Coding\\Repositorios\\MyRepositories\\Symbolic-Regression\\CSOWP_SR\\Analysis\\../algorithms\\CSOWP_SR.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m                 \u001b[0mlamb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizeConstants\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_population\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m                 \u001b[0mout_population\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsertLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_population\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 \u001b[0mlamb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmutateSExp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_population\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Documents\\Coding\\Repositorios\\MyRepositories\\Symbolic-Regression\\CSOWP_SR\\Analysis\\../algorithms\\CSOWP_SR.py\u001b[0m in \u001b[0;36moptimizeConstants\u001b[1;34m(self, me, g, Ic)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdual_annealing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\lreis\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_dual_annealing.py\u001b[0m in \u001b[0;36mdual_annealing\u001b[1;34m(func, bounds, args, maxiter, minimizer_kwargs, initial_temp, restart_temp_ratio, visit, accept, maxfun, seed, no_local_search, callback, x0, local_search_options)\u001b[0m\n\u001b[0;32m    670\u001b[0m     \u001b[1;31m# Initialization of the energy state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[0menergy_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnergyState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m     \u001b[0menergy_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_wrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrand_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m     \u001b[1;31m# Minimum value of annealing temperature reached to perform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     \u001b[1;31m# re-annealing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\lreis\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_dual_annealing.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, func_wrapper, rand_gen, x0)\u001b[0m\n\u001b[0;32m    184\u001b[0m                         \u001b[1;34m'trying new random parameters'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m                     )\n\u001b[1;32m--> 186\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m                 self.current_location = rand_gen.uniform(self.lower,\n\u001b[0;32m    188\u001b[0m                                                          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Stopping algorithm because function create NaN or (+/-) infinity values even with trying new random parameters"
     ]
    }
   ],
   "source": [
    "for optimization_kind in optimization_opts:\n",
    "    dir_path = main_path + optimization_kind\n",
    "    X, y, operators, functions = testAlgorithm(func, x_range, n_points, dir_path, population, generations,\n",
    "                                          normalize=True, const_range=const_range,\n",
    "                                          ignore_warning=True, overwrite=True, n_runs=n_runs, \n",
    "                                          functions=functions_op, operators = operators_op,\n",
    "                                          optimization_kind=optimization_kind, custom_functions_dict=custom_functions_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_kind = \"LS\"\n",
    "func = f11\n",
    "x_range = [-1,1]\n",
    "n_points = 1000\n",
    "population = 4000\n",
    "generations = 10\n",
    "const_range = (0,15)\n",
    "dir_path = \"Outputs/article_tests/F11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Outputs/article_tests/F11/PSO',\n",
       " 'Outputs/article_tests/F11/LS',\n",
       " 'Outputs/article_tests/F11/random_LS',\n",
       " 'Outputs/article_tests/F11/differential_evolution',\n",
       " 'Outputs/article_tests/F11/dual_annealing']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_opts = [\"PSO\", \"LS\", \"random_LS\", \"differential_evolution\", \"dual_annealing\"]\n",
    "main_path = \"Outputs/article_tests/F11/\"\n",
    "paths = [main_path + i for i in optimization_opts]\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs(path):\n",
    "    if not os.path.exists(path+\"/data\"):\n",
    "        os.makedirs(path+\"/data\")\n",
    "    if not os.path.exists(path+\"/trees\"):\n",
    "        os.makedirs(path+\"/trees\")\n",
    "\n",
    "for path in paths:\n",
    "    create_dirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/F11/PSO =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/F11/PSO =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/F11/PSO =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/F11/PSO =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/F11/PSO =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/F11/PSO =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/F11/LS =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/F11/LS =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/F11/LS =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/F11/LS =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/F11/LS =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/F11/LS =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/F11/random_LS =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/F11/random_LS =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/F11/random_LS =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/F11/random_LS =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/F11/random_LS =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/F11/random_LS =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/F11/differential_evolution =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/F11/differential_evolution =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/F11/differential_evolution =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/F11/differential_evolution =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/F11/differential_evolution =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/F11/differential_evolution =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/F11/dual_annealing =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 4000 and generation 10 - article_tests/F11/dual_annealing =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 4000 and generation 10 - article_tests/F11/dual_annealing =-=-=-=-=-=-=-=-\n",
      "iniciou\n"
     ]
    }
   ],
   "source": [
    "for optimization_kind in optimization_opts:\n",
    "    dir_path = main_path + optimization_kind\n",
    "    X, y, operators, functions = testAlgorithm(func, x_range, n_points, dir_path, population, generations,\n",
    "                                          normalize=True, const_range=const_range,\n",
    "                                          ignore_warning=True, overwrite=True, n_runs=n_runs, \n",
    "                                          functions=functions_op, operators = operators_op,\n",
    "                                          optimization_kind=optimization_kind, custom_functions_dict=custom_functions_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 3\n",
    "n_generations = 10\n",
    "pop_size = 40\n",
    "random_const_range = (0, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators_op = {\"+\": lambda a,b: np.add(a,b), \"*\": lambda a,b: np.multiply(a,b),\n",
    "                \"/\": lambda a,b: np.divide(a,b), \"-\": lambda a,b: np.subtract(a,b)}\n",
    "functions_op = {\"sin\": lambda a: np.sin(a), \"cos\": lambda a: np.cos(a),\n",
    "                \"square\": lambda a: a**2, \"cube\": lambda a: a**3}\n",
    "custom_functions_dict = {\"cube\": [\"(\", \")**3\"], \"square\": [\"(\", \")**2\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lreis\\AppData\\Local\\Temp\\ipykernel_16936\\4262500208.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return 0.23 + 14.2*(v+y)/(3*w)\n"
     ]
    }
   ],
   "source": [
    "def f2(v, y, w):\n",
    "    return 0.23 + 14.2*(v+y)/(3*w)\n",
    "\n",
    "v2 = np.linspace(-2, 2, 1000)\n",
    "v2 = scaler.fit_transform(np.c_[v2])\n",
    "y2 = np.linspace(-2, 2, 1000)\n",
    "y2 = scaler.fit_transform(np.c_[y2])\n",
    "w2 = np.linspace(-2, 2, 1000)\n",
    "w2 = scaler.fit_transform(np.c_[w2])\n",
    "Y2 = f2(v2, y2, w2)\n",
    "Y2 = scaler.fit_transform(np.c_[Y2]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_kind = \"LS\"\n",
    "# func = f11\n",
    "x_range = [-1,1]\n",
    "n_points = 1000\n",
    "population = 40\n",
    "generations = 10\n",
    "const_range = (0,15)\n",
    "n_runs = 3\n",
    "dir_path = \"Outputs/article_tests/F2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Outputs/article_tests/F2/PSO',\n",
       " 'Outputs/article_tests/F2/LS',\n",
       " 'Outputs/article_tests/F2/random_LS',\n",
       " 'Outputs/article_tests/F2/differential_evolution',\n",
       " 'Outputs/article_tests/F2/dual_annealing']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_opts = [\"PSO\", \"LS\", \"random_LS\", \"differential_evolution\", \"dual_annealing\"]\n",
    "main_path = \"Outputs/article_tests/F2/\"\n",
    "paths = [main_path + i for i in optimization_opts]\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs(path):\n",
    "    if not os.path.exists(path+\"/data\"):\n",
    "        os.makedirs(path+\"/data\")\n",
    "    if not os.path.exists(path+\"/trees\"):\n",
    "        os.makedirs(path+\"/trees\")\n",
    "\n",
    "for path in paths:\n",
    "    create_dirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=-=-=-=-=-=-=-= Training for population 40 and generation 10 - article_tests/F2/PSO =-=-=-=-=-=-=-=-\n",
      "iniciou\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lreis\\AppData\\Local\\Temp\\ipykernel_16936\\127597413.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"/\": lambda a,b: np.divide(a,b), \"-\": lambda a,b: np.subtract(a,b)}\n",
      "C:\\Users\\lreis\\AppData\\Local\\Temp\\ipykernel_16936\\127597413.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \"/\": lambda a,b: np.divide(a,b), \"-\": lambda a,b: np.subtract(a,b)}\n",
      "C:\\Users\\lreis\\AppData\\Local\\Temp\\ipykernel_16936\\127597413.py:1: RuntimeWarning: invalid value encountered in multiply\n",
      "  operators_op = {\"+\": lambda a,b: np.add(a,b), \"*\": lambda a,b: np.multiply(a,b),\n",
      "C:\\Users\\lreis\\AppData\\Local\\Temp\\ipykernel_16936\\127597413.py:3: RuntimeWarning: invalid value encountered in sin\n",
      "  functions_op = {\"sin\": lambda a: np.sin(a), \"cos\": lambda a: np.cos(a),\n",
      "C:\\Users\\lreis\\AppData\\Local\\Temp\\ipykernel_16936\\127597413.py:3: RuntimeWarning: invalid value encountered in cos\n",
      "  functions_op = {\"sin\": lambda a: np.sin(a), \"cos\": lambda a: np.cos(a),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 40 and generation 10 - article_tests/F2/PSO =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 40 and generation 10 - article_tests/F2/PSO =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 40 and generation 10 - article_tests/F2/PSO =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 40 and generation 10 - article_tests/F2/PSO =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 40 and generation 10 - article_tests/F2/PSO =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 40 and generation 10 - article_tests/F2/LS =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "iniciou\n",
      "-=-=-=-=-=-=-= Done training for population 40 and generation 10 - article_tests/F2/LS =-=-=-=-=-=-=-\n",
      "-=-=-=-=-=-=-=-= Training for population 40 and generation 10 - article_tests/F2/LS =-=-=-=-=-=-=-=-\n",
      "iniciou\n",
      "iniciou\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16936\\735499161.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0moutput_AEG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_AEG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msexp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Documents\\Coding\\Repositorios\\MyRepositories\\Symbolic-Regression\\CSOWP_SR\\Analysis\\../algorithms\\CSOWP_SR.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m                 \u001b[0mlamb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizeConstants\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_population\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m                 \u001b[0mout_population\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsertLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_population\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 \u001b[0mlamb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmutateSExp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_population\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Documents\\Coding\\Repositorios\\MyRepositories\\Symbolic-Regression\\CSOWP_SR\\Analysis\\../algorithms\\CSOWP_SR.py\u001b[0m in \u001b[0;36moptimizeConstants\u001b[1;34m(self, me, g, Ic)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m                 params, _ = curve_fit(me.toFunc(self._operators, self._functions, self._feature_names, self.custom_functions_dict), \n\u001b[0m\u001b[0;32m    803\u001b[0m                                       self._features[self._feature_names[0]], self.y, me.pool[-1].vector)\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\lreis\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minpack_py.py\u001b[0m in \u001b[0;36mcurve_fit\u001b[1;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, full_output, **kwargs)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[1;31m# NaNs cannot be handled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m         \u001b[0mydata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[0mydata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\lreis\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AllFloat'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    489\u001b[0m             \"array must not contain infs or NaNs\")\n\u001b[0;32m    490\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "for optimization_kind in optimization_opts:\n",
    "    dir_path = main_path + optimization_kind\n",
    "    for i in range(n_runs):\n",
    "            print(f\"-=-=-=-=-=-=-=-= Training for population {population} and generation {generations} - {dir_path[dir_path.find('/')+1:]} =-=-=-=-=-=-=-=-\")\n",
    "            SR = SymbolicRegression(generations, max_population_size=population,\n",
    "                                    max_island_count=int(population/10), random_const_range=const_range,\n",
    "                                    operators=operators_op, functions=functions_op,\n",
    "                                    optimization_kind=optimization_kind,\n",
    "                                    custom_functions_dict=custom_functions_dict)\n",
    "            SR.fit(np.c_[v2, y2, w2], Y2, feature_names=[\"v\", \"w\", \"y\"])    \n",
    "            \n",
    "            start_time = time()\n",
    "            output_AEG = SR.predict()\n",
    "            end_time = time()\n",
    "            data = SR.evaluate_tree(output_AEG.sexp)\n",
    "            \n",
    "            print(f\"-=-=-=-=-=-=-= Done training for population {population} and generation {generations} - {dir_path[dir_path.find('/')+1:]} =-=-=-=-=-=-=-\")\n",
    "\n",
    "            # Writing the data =================================\n",
    "\n",
    "            # In case the output is a constant function\n",
    "            if data.shape[0] == 1:\n",
    "                data = np.array([data[0] for i in range(0, 1000)])\n",
    "\n",
    "            # data = pd.DataFrame(np.c_[X, data], columns=[\"x\", \"y\"])\n",
    "            # data.to_csv(dir_path + f\"/data/data-{population}.csv\", sep=\",\", index=False)\n",
    "\n",
    "            # graph = output_AEG.sexp.visualize_tree()\n",
    "            # graph.render(dir_path + f\"/trees/tree-{population}\", format=\"svg\")\n",
    "\n",
    "            with open(dir_path + f\"/trees/tree-{population}-{generations}-{i}\", \"wb\") as file:\n",
    "                pickle.dump(output_AEG.sexp, file)\n",
    "\n",
    "            with open(dir_path + \"/results.csv\", \"a\") as file:\n",
    "                file.write(f\"{SR.fitness_score(output_AEG)},{population},{generations},{end_time - start_time},{i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"77pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 76.89 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 72.89,-184 72.89,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"34.45\" cy=\"-162\" rx=\"33.6\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34.45\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">square</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"34.45\" cy=\"-90\" rx=\"27.1\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34.45\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">cube</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M34.45,-143.7C34.45,-135.98 34.45,-126.71 34.45,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"37.95,-118.1 34.45,-108.1 30.95,-118.1 37.95,-118.1\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"34.45\" cy=\"-18\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34.45\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v, w, y</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M34.45,-71.7C34.45,-63.98 34.45,-54.71 34.45,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"37.95,-46.1 34.45,-36.1 30.95,-46.1 37.95,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x216d0bf0370>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"Outputs/article_tests/F2/PSO/trees/tree-40-10-1\", \"rb\") as file:\n",
    "    tree = pickle.load(file)\n",
    "tree.visualize_tree()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
